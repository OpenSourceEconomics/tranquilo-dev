\subsubsection{Aggregation}
\label{subsubsec:aggregation}
\hfill\\


% \begin{itemize}
%     \item for aggregation the fitting method does not matter, only the presence of hessian does
%     \item discuss how dfgn does aggregation, but that we follow dfols for linear residuals. In aggregation, only difference between dfols and dfgn is 1/2 in the formulation of the problem
%     \item

%     \begin{itemize}
%         \item non linear least-squares problems
%         \item local linear interpolation models to approximate jacbian
%         \item approximate residuals with linear models.
%         \item the scalar model is the square of the 2-norm, like in tranquilo.
%     \end{itemize}
%     \item pounders for quadratic linear models
%     \item identity for scalar optimization
%     \item formulas for the scalar model for linear(dfols) and square residual models (pounders)
% \end{itemize}


In the trust region literature, aggregation strategy implemented by the function $Aggregate$ in \ref{eq:aggregate} takes into account the degree of the polynomial residual models $M_t^i$, but abstracts from the fitting methods discussed in \ref{subsubsec:fitting}.

With linear vector model $M_t^v$, we follow DF-OLS by building the scalar model $M_t^s$ through substitution of $r^i$ by $M_t^i$ in the definition of the full objective function (\ref{eq:problem-ls-det}):
\begin{align}
    M_t^s(s)\equiv\sum\limits_{i=1}^k(M_t^i(s))^2 =  c_t^s+g^s_ts^T+\frac{1}{2}s^TH^s_ts
\end{align}
where:
\begin{align}
    c_t^s &\equiv\sum\limits_{i=1}^k(M_t^i(x_t^*))^2 = \sum\limits_{i=1}^k(r^i(x_t^*))^2\label{eq:scalar-intercept}\\
     g^s_t&\equiv2\sum\limits_{i=1}^k(g_t^i(x_t^*)M_t^i(x_t^*))=2\sum\limits_{i=1}^kg_t^i(x_t^*)r^i(x_t^*)\label{eq:scalar-gradient}\\
     H_t^s&\equiv2\sum\limits_{i=1}^kg_t^i(x_t^*)(g_t^i(x_t^*))^T\label{eq:scalar-hessian}
\end{align}
In equations \ref{eq:scalar-intercept} and \ref{eq:scalar-hessian}, the substitution of $M_t^i(x_t^*)$ by $r^i(x_t^*)$ is done under the assumption that $x_t^*$ belongs to the set of model points and thus $M_t^i(x_t^*)=r^i(x_t^*)$.

With quadratic residual models, POUNDERS obtains an aggregate model using a "full Newton" approach. The full Newton model approximates the scalar model obtained by direct substitution of the residual function by a second order Taylor expansion around the current candidate point $x_t^*$:
\begin{align}
    M^s_t(s)\equiv\sum\limits_{i=1}^k(M_t^i(s))^2\approx c_t^s+g^s_ts^T+\frac{1}{2}s^TH^s_ts
    \label{eq:taylor-exp}
\end{align}
where $c_t^s$ and $g_t^s$ are defined as in \ref{eq:scalar-intercept} and \ref{eq:scalar-gradient}, respectively, and:
\begin{align}
     H_t^s&\equiv2\sum\limits_{i=1}^k(g_t^i(x_t^*)(g_t^i(x_t^*))^T+H_t^i(x_t^*)M_t^i(x_t^*))=2\sum\limits_{i=1}^k(g_t^i(x_t^*)(g_t^i(x_t^*))^T+H_t^i(x_t^*)r^i(x_t^*))\label{eq:scalar-hessian-quadratic}
\end{align}

An alternative approach is implemented in DFBOLS \citep{Zhang2010}, where the second order term of the scalar model is regularized based on cut-offs on the intercept and the linear terms. The regularization is designed to provide fast local convergence for problems with sparse residuals \citep{Zhang2010}. In our applications, since we assume problems with non-trivial residuals, we use the POUNDERS aggregation strategy.

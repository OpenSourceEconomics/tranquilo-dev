\section{Parallelization}\label{sec:parallelization}

In this section we describe what parallelization features our algorithm offers and how they are
implemented. We also discuss the cost model that is used when comparing the performance of our
parallelized algorithm to serial algorithms. We refrain from an analysis of a parallelized objective
function and consider the case where the parallelization solely takes place at the optimization
algorithm level.

We parallelize at three places in the algorithm. (1) At the beginning of the optimization, where we
are able to parallelize the repeated evaluation of the starting point. (2) During the sampling,
where we are able to parallelize the evaluations at different sampling points. And, (3) during the
acceptance step, where we can utitilize unused resources during the acceptance point evaluation.

\textcolor{red}{List other algorithms that parallelize and how they compare to the three categories
(DFOLS, Parallel-Neldermead)}

Tranquilo offers the possibility to set the number of threads for the parallelization
(\texttt{n\_cores}), and the size of an evaluation batch (\texttt{batch\_size}). By default, the
\texttt{batch\_size} is equal to \texttt{n\_cores}, but it can also be set to any larger value. The
following parallelization strategies are motivated by the assumption, that one evaluation is as
time-consuming as performing \texttt{batch\_size} many.\footnote{Using different arguments for the
number of threads and the batch size allows us to use a single-core machine to test the algorithm's
behavior on a machine with many cores, by setting the batch size to the number of available cores on
the many-cores machine.} It is therefore always preferred to evaluate a number of points that is
divisible by the \texttt{batch\_size}. For a given number we define the smallest multiple of the
\texttt{batch\_size} that is larger or equal to the number in question as the \emph{next multiple}
of that number. As an example, the next multiple of $\texttt{batch\_size} + 1$, is $2 \times
\texttt{batch\_size}$.

\subsection{Implementation}\label{subsec:parallelization::implementation}

\subsubsection{At Start}

Parallelization at the start of the algorithm occurs only for noisy problems. In this noisy case,
the argument \texttt{n\_evals\_at\_start} describes the number of evaluations that are performed at
the starting values to average out the noise. In the parallel case this number is replaced by its
next multiple.

\subsubsection{Sampling}

In line 5 \textcolor{red}{(this is hardcoded atm)} of Listing \ref{algo:core} new points are
sampled. When parallelization is enabled, instead of sampling the requested number of points, we
sample the next multiple of it.

\subsubsection{Acceptance Step}

\textcolor{red}{This will be updated once the acceptance step section is written.}

\begin{itemize}
    \item if batch size is 1 (no parallelization): do classic acceptance based on rhos
    \item else, check if the candidate point is at the tr border
    \item if yes, get number of line search points (at most 3, at least batch size-1) and define the
        grid on the line
    \item calculate number of unallocated function evals based on the number of points on the line
        search and batch size ($batch\_size-1-n_evals_line_search$) \comment[id=MP]{WHY
        $batch\_size-1$ ?}
    \item if the previous number is non-zero, do speculative sampling around the candidate point
        using search radius
    \item add the line search and speculative points, if any, to the history
    \item check if criterion is smaller at any of the new points (spec+line search)
    \item if so, update candidate fval and x
    \item insert algorithm listing at the end
\end{itemize}

\subsection{Benchmarking}\label{subsec:parallelization::benchmarking}

The benchmark plots look have to be adjusted for the parallel case, as the number of criterion
evaluations does not provide a good measure of runtime anymore. Instead, we use the number of batch
evaluations as a proxy for runtime, in line with our parallel cost model. This reflects our
assumption that in the parallel case the evaluation of a batch takes as much time as the evaluation
at a single point.


\begin{figure}\label{fig:benchmark_parallel}
    % \includesvg{bld/figures/profile_plots/parallelization_ls}
    \caption{Comparison of parallel optimizers.}
\end{figure}

\section{Parallelization}\label{sec:parallelization}

In this section we describe what parallelization features our algorithm offers and how they are
implemented. We also discuss the cost model that is used when comparing the performance of our
parallelized algorithm to serial algorithms. We refrain from an analysis of a parallelized objective
function and consider the case where the parallelization solely takes place at the optimization
algorithm level.

We parallelize at three places in the algorithm. (1) At the beginning of the optimization, where we
are able to parallelize the repeated evaluation of the starting point. (2) During the sampling,
where we are able to parallelize the evaluations at different sampling points. And, (3) during the
acceptance step, where we can utitilize unused resources during the acceptance point evaluation.

\textcolor{red}{List other algorithms that parallelize and how they compare to the three categories
(DFOLS, Parallel-Neldermead)}

Tranquilo offers the possibility to set the number of threads for the parallelization $n_c$, and the
size of an evaluation batch $n_b$.

The Tranquilo algorithm offers two options to govern the parallelization behavior. The first option,
number of cores $n_c$, determines the number of threads that are used for parallelization. The
second option, batch size $n_b$, determines the number of criterion evaluations we try to perform
simultaneously. In most cases, $n_b = n_c$ is a good choice, but we allow for the
possibility to set $n_b$ to a larger value.\footnote{Using different options for the number of
threads and the batch size allows us to use a single-core machine to test the algorithm's behavior
on a machine with many cores, by setting the batch size to the number of available cores on the
many-cores machine.} The following parallelization strategies are motivated by the assumption, that
one criterion evaluation is as time-consuming as performing $n_b$ many. It is therefore always
preferred to evaluate a number of points that is divisible by $n_b$. For any integer we define
the smallest multiple of $n_b$ that is larger or equal to that number in question as the \emph{next
multiple} of that number with basis $n_b$. Since we only consider the case where $n_b$ is the basis,
we will refrain from writing this explicit. As an example, the next multiple of $n_b + 1$, is $2
\times n_b$.

\subsection{Implementation}\label{subsec:parallelization::implementation}

\subsubsection{At Start}

Parallelization at the start of the algorithm occurs only for noisy problems. In the noisy case, the
option $n_{\text{evals at start}} \in \mathbb{N}$ describes the number of evaluations that are
performed at the starting value to average out noise. In the parallel case this number is replaced
by its next multiple.

\subsubsection{Sampling}

In line \ref{algo:core::sampling} of Listing \ref{algo:core} (\textcolor{red}{This will refer to the
new listing posted here}) new points are sampled. When parallelization is enabled, instead of
sampling the requested number of points, we sample the next multiple of it.

\subsubsection{Acceptance Step}

\textcolor{red}{This will be updated once the acceptance step section is written.}

\begin{itemize}
    \item if batch size is 1 (no parallelization): do classic acceptance based on rhos
    \item else, check if the candidate point is at the tr border
    \item if yes, get number of line search points (at most 3, at least batch size-1) and define the
        grid on the line
    \item calculate number of unallocated function evals based on the number of points on the line
        search and batch size ($batch\_size-1-n_evals_line_search$) \comment[id=MP]{WHY
        $batch\_size-1$ ?}
    \item if the previous number is non-zero, do speculative sampling around the candidate point
        using search radius
    \item add the line search and speculative points, if any, to the history
    \item check if criterion is smaller at any of the new points (spec+line search)
    \item if so, update candidate fval and x
    \item insert algorithm listing at the end
\end{itemize}

\subsection{Benchmarking}\label{subsec:parallelization::benchmarking}

The benchmark plots look have to be adjusted for the parallel case, as the number of criterion
evaluations does not provide a good measure of runtime anymore. Instead, we use the number of batch
evaluations as a proxy for runtime, in line with our parallel cost model. This reflects our
assumption that in the parallel case the evaluation of a batch takes as much time as the evaluation
of a single point.

\textcolor{red}{
\begin{enumerate}
    \item Fix figure
    \item Describe figure
\end{enumerate}
}


\begin{figure}[ht]\label{fig:parallelization::benchmark}
    \includegraphics[scale=0.9]{../bld/figures/profile_plots/parallelization_ls}
    \caption{Benchmark plots for the parallel cost model.}
\end{figure}

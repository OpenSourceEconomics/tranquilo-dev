
\subsection{The trust region framework}
\label{subsec:tr-framework}
%%TODO
% 1. define notation for the building blocks write equations for the interface and data flow
% 2. write down algorithm listing
In this section we review the general trust region framework and the main components of the Tranquilo algorithm. The specific functional forms the algorithm components are further discussed in section \ref{subsec:core-implementation}. We provide the full statement of Tranquilo in Algorithm \ref{algo:core}.

\begin{algorithm}[H]
    \caption{Tranquilo algorithm}\label{algo:core}
    \KwIn{
    Starting point $x^*_0\in\mathbb{R}^p$, initial trust region radius $\Delta^{region}_0$, and target sample size $n^{target}$.

    Other constants: Search factor $\gamma^{search}$, minimum step size $s^{min}$, relative improvement cut-offs $0<\rho^{1}<\rho^2$, trust region expansion and shrinking factors $0<\gamma^{dec}<1<\gamma^{inc}$, and maximum number of iterations $t^{max}$

    A convergence criterion.

    Build initial sample $\mathcal{S}_0\subset B(x_0,\Delta_0^{region})$ with $|\mathcal{S}_0|=n^{target}$



    }
    \For{t=0,1,2,...}{
        Given $x_t^*$ and $\Delta_t^{search}=\gamma^{search}\Delta^{tr}_{t}$, scan history for points in the search region: $\mathcal{S}^{existing}_t = \{x\in\mathcal{H}|\Hquad\lVert x^*_t-x\rVert\leq\Delta^{search}_t\}$\\
        Filter existing points: $\mathcal{S}^{filtered}_t\equiv Filter (\mathcal{S}^{existing}_t) = \{ Filter (x)|\Hquad x\in \mathcal{E}_t\}$\\
        \If{$|S_t^{filtered}|<n^{target}$}{
            Sample new points in the trust region: $\mathcal{S}^{new}_t\equiv Sample(\mathcal{S}_t^{filtered},B_t,n^{target})$
        }
        Given $\mathcal{S}^{model}_t\equiv\mathcal{S}^{filtered}_t\cup\mathcal{S}^{new}_t$, build the vector model $M_t^v\equiv Fit(x_t;r,B_t)$\label{algo-core-line:fit}\\
        Aggregate the vector model: ${M}_t^s = Aggregate(M_t^v)$\label{algo-core-aggregate}\\
        Solve for the optimum of the scalar model $M_t^s$: $s_t\approx arg\,\min\limits_sM_t^s(x_t+s)$\label{algo-core-line:solve}\\
        \If{$|\mathcal{S}_t|>n^{target}$}{
            \While{$\lVert s_t\rVert\leq s^{min}$}{
                Drop sample points\\
                Build a vector model: $M_t^v\equiv Fit(x_t;r,B_t)$\\
                Aggregate the vector model: ${M}_t^s = Aggregate(M_t^v)$\\
                Solve for the optimum of the scalar model: $M_t^s$: $s_t\approx arg\,\min\limits_sM_t^s(x_t+s)$\\
                }
        }

        \While{$\lVert s_t\rVert\leq s^{min}$}{
            Drop and resample points\\
            Build a vector model: $M_t^v\equiv Fit(x_t;r,B_t)$\\
            Aggregate the vector model: ${M}_t^s = Aggregate(M_t^v)$\\
            Solve for the optimum of the scalar model: $M_t^s$: $s_t\approx arg\,\min\limits_sM_t^s(x_t+s)$\\
        }
         Calculate $\Delta f_t\equiv f(x_t^*) - f(x_t^*+s_t)$ and $\Delta M^{s}_t\equiv M_t^s(x_t^*) - M_t^s(x_t^*+s_t)$\\
         \nonl \textbf{Acceptance decision}:\\
         $(Decision_t,x_{t+1}^*,\rho_t;\Hquad\cdot\Hquad) =  Accept(s_t,x_t^{*},\Delta f_t,\Delta M_t^s;\Hquad\cdot\Hquad)$\\
         \uIf{$\rho_t\geq\rho^{2}$ and  $s_t$ is large}{
         Expand trust region radius: $\Delta^{region}_{t+1}=\gamma^{inc}\Delta^{region}_t$

        }
        \uElseIf{$\rho_t>\rho^1$}{
        Leave the radius unchanged: $\Delta_{t+1}^{region}=\Delta_t^{region}$
        }
        \uElse{
        Shrink trust region radius $\Delta^{region}_{t+1}=\gamma^{dec}\Delta^{region}_t$
        }
    \If{$t>t^{max}$ or $converged$}{\textbf{break}}
    }

    \end{algorithm}

\newpage
At the beginning of every iteration, we are equipped with the following information:

\textit{Candidate point} $x_t^*\in\mathbb{R}^p$.

\textit{Trust region} defined by its radius $\Delta_t^{region}$ and center $x_t\in\mathbb{R}^p$ as follows:
\begin{align}
    B(x_t,\Delta_t^{region})\equiv\{x\in\mathbb{R}^p|\Hquad\lVert x-x_t\rVert\leq\Delta_t^{region}\}
    \label{eq:def-trustregion}
\end{align}
where $\lVert\cdot\rVert$ denotes the 2-norm of a vector.

\textit{History} of function evaluations $\mathcal{H}_t$.

\textit{Constants} 1) Target sample size $n^{target}$, 2) Search factor, $\gamma^{search}$, 3) Trust region radius adjustment factors $0<\gamma^{dec}<1<\gamma^{inc}$, 4) The function value improvement cutoffs for trust region radius adjustment, $0<\rho^1<\rho^2$, and 5) minimum step length $s^{min}$

\paragraph{The main loop} We start the iteration by approximating the residual vector by fitting a surrogate vector model to a set of model points $\mathcal{S}^{model}=\{x_t^*,x_1,\dots,x_{n_{t}-1}\}\subset\mathbb{R}^p$:
\begin{align}
    r(x_t^*+s)\approx M_t^v(s)
    \label{eq:vec-model}
\end{align}
where $M_t^v = \{M_t^i,\dots,M_t^i\}$, and the residual models $M^i_t$ can be polynomial of up to second degree. Note that we center the vector model around the current candidate point $x_t^*$.

The Tranquilo fitting function is can be applied to both underdetermined (when $n_t$ is smaller than the degrees of freedom of the residual models), just determined ($n_t=DoF(M^i)$) and over determined ($n_t>DoF(M^i_t))$ regression problems.
\begin{align}
    M_t^v\equiv Fit(x_t;r,B_t)
    \label{eq:fit-model}
\end{align}
where the additional dependency on the trust region $B_t$ is necessary to scale the model to a unit circle to facilitate solving for the minimum of the scalar model.

With its flexible fitting function Tranquilo thus nests the problems solved in DF-OLS (linear over-determined regression) and POUNDERS (quadratic underdetermined interpolation).

To obtain the model points $\mathcal{S}^{model}_t$, we first search the history of function evaluations for points that lie within $\Delta_t^{search}=\gamma^{search}\Delta_t^{search}$ neighborhood of the candidate point $x_t^*$:
\begin{align}
    \mathcal{S}^{existing}_t\equiv\{x\in\mathcal{H}|\Hquad\lVert x^*_t-x\rVert\leq\Delta^{search}_t\}
    \label{eq:hist-search}
\end{align}
We filter the set of existing points to improve the quality of the sample geometry:
\begin{align}
    \mathcal{S}^{filtered}_t\equiv Filter (\mathcal{S}^{existing}_t) = \{ Filter (x)|\Hquad x\in \mathcal{S}^{existing}_t\}
    \label{eq:filtering}
\end{align}
Where the filter function can be applied to, for example, detect clusters and return the corresponding centers, discard points outside of the trust region, or do nothing by returning $\mathcal{S}_t^{existing}$.
\comment[id=MP]{TODO Mariam: add examples from /refer to wild paper}

If the size of the filtered sample is smaller than the target sample size $n^{target}$, we sample new points in the current trust region:

\begin{align}
    \mathcal{S}^{new}_{t}\equiv Sample(\mathcal{S}_t^{filtered},B_t,n^{target})
    \label{eq:sample-points}
\end{align}
where the sampling function nests several strategies for sampling either in the interior or on the hull of the trust region.

Having built the vector model $M_t^v$, we approximate the full criterion function $f$ by aggregating $M_t^v$ into a scalar model:
\begin{align}
    M_t^s = Aggregate(M_t^v)
\end{align}
where the $Aggregate$ function allows for different aggregation strategies fit for different problems.

To find a candidate step $s_t$, we approximately solve for the optimum of the aggregate model in the current trust region:
\begin{align}
    s_t\approx arg\,\min\limits_{\lVert s\rVert<=\Delta_t^{region}}M_t^s(x_t+s)
    \label{eq:cand-step}
\end{align}

We impose a lower threshold on the step size $\lVert s_t\rVert$ to accept a candidate step. To this end, we iteratively improve sample quality, fit the model and solve \ref{eq:cand-step} until we obtain a large enough candidate step.

We evaluate the aggregate criterion $f$ at $x^{*}_t+s_t$, and compute the decrease in the objective produced by the candidate step:
\begin{align}
    \Delta f_t\equiv f(x_t^*) - f(x_t^*+s_t)
    \label{eq:actual-improvement}
\end{align}

Similarly, we compute the expected improvement predicted my the aggregate model:
\begin{align}
    \Delta M^{s}_t\equiv M_t^s(x_t^*) - M_t^s(x_t^*+s_t)
    \label{eq:expected-improvement}
\end{align}

In a comprehensive acceptance step, details of which we will discuss in sections \ref{subsubsec:acceptance} (\textcolor{red}{add references to sections of acceptance details in noisy and parallel cases}), we take into account the actual and expected improvements $\Delta f_t$ and $\Delta M_t^s$, to obtain the candidate point for the next iteration $x_{t+1}^*$ and the relative improvement $\rho_t\equiv \Delta f_t/ \Delta M^s_t$:

\begin{align}
    Accept(s_t,x_t^{*},\Delta f_t,\Delta M_t^s;\Hquad\cdot\Hquad)=(Decision_t,x_{t+1}^{*},\rho_t;\Hquad\cdot\Hquad)
    \label{eq:acceptance-core}
\end{align}
The $Accept$ function nests the classical trust region acceptance step:
\begin{align}
    x_{t+1}^*=\begin{cases}
        x_t^*+s_t,\quad&\rho_t\geq\rho^{min}\\
        x_t^*,\quad&\rho_t<\rho^{min}
    \end{cases}
    \label{eq:accept-classic}
\end{align}
as a special case.

Having obtained the acceptance results, we expand the trust region radius for the next iteration to $\Delta_{t+1}^{region}=\gamma^{inc}\Delta_t^{region}$ if both the ratio $\rho_t$ and the step size $\lVert s_t\rVert$ are sufficiently large. For low values of $rho_t$, we shrink the radius to $\Delta^{region}_{t+1} = \gamma^{dec}\Delta_t^{region}$
